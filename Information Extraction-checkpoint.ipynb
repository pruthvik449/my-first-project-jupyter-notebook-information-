{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e9249b-2c76-4287-a015-9de5adbd4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Information for C:/Users/pruth/AppData/Roaming/Jupyter/runtime/MLpaper1.pdf:\n",
      "Authors: ['SUPRIYA V. MAHADEVKAR1', 'ABDELKAREIM GABRALLA', 'Nourah Bint', 'PNURSP2022R178', 'Zhongyi Guo\\n ', 'https://creativecommons.org/licenses/by/4.0/107293S. V. Mahadevkar', 'Scipy', 'Matplotlib', 'Keras', 'Kadane', 'Tensor Flow', 'V. Mahadevkar', 'CV', 'Spam', 'V. Mahadevkar', 'CV', 'V. Mahadevkar', 'Denny M.R', 'Vanderplas', 'Pu', 'Chen', 'Chen', 'Vygotsky', 'James Britton', 'Seltzer Donald S.', 'Littlestone Nick', 'Vladimir Vapnik', 'Primary', 'Supervised', 'V. Mahadevkar', 'Supervised', 'V. Mahadevkar', 'V. Mahadevkar', 'MIL', 'V. Mahadevkar', 'V. Mahadevkar', 'V. Mahadevkar', 'AwA', 'V. Mahadevkar', 'V. Mahadevkar', 'Deep', 'V. Mahadevkar', 'V. Mahadevkar', '107309S. V. Mahadevkar', 'ed\\ndatasets', 'Markov', 'V. Mahadevkar', 'Areas', 'V. Mahadevkar', 'V. Mahadevkar', 'V. Mahadevkar', 'Transfer', 'V. Mahadevkar', 'V. Mahadevkar', 'Talking Heads', 'Generative Model-Based', 'Accuracy', 'V. Mahadevkar', 'VQ', '107319S. V. Mahadevkar', 'Gboard', 'Gboard', 'Trans-\\nfer learning', 'Transfer', 'V. Mahadevkar', 'V. Mahadevkar', 'V. Mahadevkar', 'V. Mahadevkar', 'G. HIGH OPERATIONAL', 'Transfer', 'CV', 'T. Yu', 'T. Kolekar', 'S. Patil', 'A. Zaguia', 'C. Prakash', 'B. Bhushan', 'G. Dhiman', 'W. Viriyasitavat', 'S. A. Awan', 'Scalable Inf', 'M. López', 'Quart', 'J. Exp', 'C. H. Chen', 'R. D. Odom', 'M. Byassee', 'J. Reading Behav', 'R. T. Johnson', 'K. A. Smith', 'J. Excellence', 'V. N. Balasubramanian', 'C. V. Jawahar', 'J. Indian Inst', 'Jun.', 'C. Janiesch', 'R. Masood', 'S. Seneviratne', 'Jun.', 'R. Knani', 'F. Hamdaoui', 'A. Mtibaa', 'J. Debnath', 'N. R. Chakraborty', 'Commun', 'Technol', 'J. D. Prusa', '107325S. V. Mahadevkar', 'T. S. Gunawan', 'M. H. Habaebi', 'M. Kartiwi', 'R. Ahmad', 'N. Doulamis', 'A. Doulamis', 'E. Protopapadakis', 'W. Ouyang', 'X. Wang', 'P. Fieguth', 'J. Chen', 'X. Liu', 'M. Pietikäinen', 'J. Comput', 'B. Zheng', 'S. W. Yoon', 'H. S. Ko', 'J. Oper', 'Jun.', 'S. A. Jiwani', 'B. Rajitha', 'Spam', 'Mater', 'G. Xu', 'Z. Shuai', 'S. Saminu', 'I. Javaid', 'I. Salim\\nAhmad', 'Brain Sci.', 'N. Jorge', 'G. K. Moorthy', 'S. P. Mohanty', 'R. R. de Castañeda', 'Intell', 'F. Ullah', 'M. J. Thaheem', 'A. Maqsoom', 'Drones', 'P. van der', 'Smagt', 'J. Bayer', 'Carbonneau', 'V. Cheplygina', 'E. Granger', 'G. Gagnon', 'Y. Chen', 'J. Bi', 'J. Z. Wang', 'MILES', 'Mach', 'Intell', 'C. Yang', 'T. Lozano-Perez', 'M. de Bruijne', 'J. P. Pluim', 'W. Guo', 'S. Ninomiya', 'V. N. Balasubra-', 'Mach', 'E. Krivosheev', 'J. Yang', 'A. Passerini', 'F. Casati', 'Artif', 'A. Nurnberger', 'J. M. Kohler', 'P. Sen', 'M. Liu', 'K. Grauman', 'R. Urtasun', 'T. Darrell', 'D. McDuff', 'R. E. Kaliouby', '] K. Kim', 'K. I. Kim', 'S. Y. Chun', 'Jun.', 'C. Liu', 'W. Shen', 'A. Yuille', 'J. Eusebio', 'S. Chakraborty', 'S. Panchanathan', 'M. H. Amini', 'H. R. Arabnia', 'T. Xiang', 'S. Gong', 'Q. Mary', 'http://openaccess.thecvf.com/content_cvpr_2017/papers/Kod\\nirov_Semantic_Autoencoder_for_CVPR_2017_paper.pdf\\n', 'C. Blundell', 'T. Lillicrap', 'K. Kavukcuoglu', 'D. Wierstra', 'Neural Inf', 'W. Y. Chen', 'Y. C. F. Wang', 'Y. C. Liu', 'Z. Kira', 'J. B. Huang', 'Y. Gal', 'R. Cipolla', 'H. Li', 'X. Shen', 'X. Liang', 'Y. Wu', 'J. Yang', 'Y. Liu', 'M. Qian', 'C. Guan', 'K. G. Quach', 'D. Truong', 'M. Savvides', 'Conf', 'J. Xu', 'L. Xiao', 'A. M. López', 'R. J. Chen', 'J. Wang', 'F. Mahmood', 'S. Karanam', 'D. Kumar', 'Man', 'Jun.', 'J. Yang', 'J. Zhao', 'Algorithms', 'T. Imielinski', 'A. Swami', 'P. Subashini', 'M. Krishnaveni', 'Intell', 'L. Van Gool', 'C. K. I. Williams', 'J. Winn', 'A. Zisserman', 'J. Comput', 'Jun.', 'V. Mahadevkar', 'A. Swami', 'R. Srikant', 'M. Karimi', 'S. Lazebnik', 'G. Maicas', 'A. P. Bradley', 'J. C. Nascimento', 'I. Reid', 'Springer-Verlag', 'B. Georgescu', 'Y. Zheng', 'S. Grbic', 'A. Maier', 'J. Hornegger', 'Mach', 'Intell', 'B. Kainz', 'C. Yeh', 'S. Ermon', 'Nguyen', 'K. Hoang-Nguyen', 'A. Khoreva', 'R. Benenson', 'B. Schiele', 'A. Sorkine-Hornung', 'Z. Wu', 'Y. Tian', 'H. Wang', 'Z. Zhang', 'J. Tang', 'B. Luo', 'Jun.', 'R. G. Lopes', 'B. Cheng', 'M. D. Collins', 'E. D. Cubuk', 'H. Adam', 'J. Shlens', 'W. S. Lee', 'Conf', 'X. Shen', 'M. Aubry', 'Jun.', 'K. Gupta', 'L. H. Chang', 'H. Najjaran', 'P. Christodoulou', 'L. Doitsidis', 'Z. Qi', 'K. Duan', 'D. Xi', 'Y. Zhu', 'H. Zhu', 'H. Xiong', 'Q. He', 'S. K. Khaitan', 'A. Choudhary', 'A. Agrawal', 'Building Mater', 'C. Zhou', 'P. Hansen', 'S. K. Venkataramanaiah', 'M. Mattina', 'M. Piekarski', 'D. Kucharski', 'J. Jaworek-Korjakowska', 'M. Gorgon', 'D. R. Faria', 'E. Frank', 'C. J. Pal', 'Y. Yilmaz', 'Y. Yu', 'H. Liu', 'M. Fu', 'J. Chen', 'X. Wang', 'K. Wang', 'Jun.', 'M. Castejón-Limas', 'L. Sánchez-González', 'L. Fernández-Robles', 'H. Perez', 'J. Diez-Gonzalez', 'Strong', 'R. Timofte', 'I. Bax', 'G. Heidemann', 'H. Ritter', 'Joint Pattern\\n', 'C. H. Lampert', 'B. Schiele', 'Z. Akata', 'Mach', 'Intell', 'B. Catanzaro', 'G. Gupta', 'Y. Li', 'M. Xia', 'J. Wu', 'M. Lu', 'S. Zhang', 'L. Weng', 'Z. Tang', 'K. Bhogaraju', 'L. Shen', 'X. Chu', 'S. Avestimehr', 'X. Wu', 'Y. Luo', 'A. Huang', 'Y. Huang', 'Y. Liu', 'Q. Yang', 'B. Yan', 'J. Wang', 'J. Cheng', 'Y. Zhou', 'Y. Zhang', 'Y. Yang', 'L. Liu', 'H. Zhao', 'C. Wang', 'B. Liu', 'Commun', 'M. P. Schoen', 'Technol', 'P. van der', 'Smagt', 'J. Bayer', 'V. Mahadevkar', 'A. Shimazu', 'L. M. Nguyen', 'A. Gupta', 'Front', 'Artif', 'Y. Zhang', 'Z. Wu', 'H. Peng', 'S. Lin', 'Jun.', 'H. Zeng', 'A. Li', 'E. W. T. Ngai', 'Mach', 'Learn', 'G. Heidemann', 'H. Ritter', 'Lett', 'X. Li', 'Y. Grandvalet', 'F. Davoine', 'J. Cheng', 'Y. Cui', 'H. Zhang', 'S. Belongie', 'Tsai', 'Yang', 'W. Wang', 'Jun.', 'C. Zhang', 'Y. Ma', 'S. Xu', 'X. Wang', 'Q. Zhu', 'Intell', 'W. Li', 'R. Li', 'L. Zhang', 'Q. Jin', 'D. Wang', 'H. Yu', 'G. Sun', 'S. Luo', 'X. Zhai', 'A. Oliver', 'A. Kolesnikov', 'L. Beyer', 'D. Gandhi', 'Y. Han', 'Y. L. Park', 'A. Gupta', 'J.', 'degree', 'Bandra', 'V. Mahadevkar', 'DEEPALI R. VORA', 'Inderscience', 'Mohamed Ali Professorial Chair', 'ABDELKAREIM GABRALLA', 'M.Sc.', 'Nourah Bint']\n",
      "Publication Year: 2022\n",
      "Methods: methods use the machine\n",
      "learning algorithms such as support vector machine, KNN\n",
      "etc. Scipy, Scikit, OpenCV, Matplotlib and Keras are the\n",
      "popular are libraries used for image segmentation.For object detection previously sliding window, selective\n",
      "search and Kadane's algorithms were used but now most\n",
      "of the application areas uses deep learning algorithms like\n",
      "RCNN,YOLO,SSD for object detection in CV. The software\n",
      "libraries utilized in object detection for computer vision are\n",
      "Tensor Flow, ImageAI, GluonCV and YOLOv7. Convolution\n",
      "neural networks, recurrent neural networks, long short-term\n",
      "memories, gated recurrent units, and Bayesian networks are\n",
      "all used in traf\u001c",
      "c detection models. Sensors in intelligent\n",
      "settings collect data that is later analyzed and forecasted.\n",
      "One of the tasks the convolution neural network (CNN)\n",
      "successfully completes for successful object detection is\n",
      "feature extraction [3]. With a big collection of face pho-\n",
      "tos, a deep convolution neural network can recognize faces\n",
      "through supervised learning. Data annotation and labeling is\n",
      "the only problem in computer vision and machine learning\n",
      "applications. The support vector machines, neural networks,\n",
      "KNN and probabilistic graphical models machine learning\n",
      "paradigms for computer vision. A common classi\u001c",
      "cation\n",
      "technique is support vector machines (SVMs), a sub\u001c",
      "eld of\n",
      "supervised machine learning techniques. With a maximum\n",
      "margin separating two signi\u001c",
      "cant classifed classes, SVMs\n",
      "seek to locate a hyperplane [4]. Layered networks of con-\n",
      "nected processing nodes make up a neural network. A class of\n",
      "neural networks called convolution neural networks (CNNs)\n",
      "is utilized for image recognition and categorization. It has\n",
      "neurons that are wide, large, and deep. Due to widely avail-\n",
      "able datasets, GPUs, and regularization approaches, CNN has\n",
      "become more and more popular in recent years.\n",
      "The paper looks at a variety of machine learning applica-\n",
      "tions in computer vision. For instance, biological sciences\n",
      "include segmentation, feature extraction, pattern match-\n",
      "ing, visual model optimization, form representation, surface\n",
      "reconstruction, and modeling. Computer vision uses machine\n",
      "learning to evaluate data from images that detect cars and\n",
      "pedestrians, using images to analyze remote sensing data\n",
      "for geographic information systems, diagnose faults in rail-\n",
      "road ties automatically, identify different varieties of mango\n",
      "fruit based on size attributes, and extract graphical and tex-\n",
      "tual information from document images [5]. Detecting curb\n",
      "ramps in Google Street View, automatically detecting and\n",
      "identifying faces, machine vision, handwriting recognition,\n",
      "enhanced driving assistance systems, and behavioral mea-\n",
      "sures are some of the other techniques. Computer vision and\n",
      "machine learning are also used in the medical \u001c",
      "eld, espe-\n",
      "cially in nuclear medicine, endoscopy, angiography, mag-\n",
      "netic resonance, ultrasound, and microscopy, according to\n",
      "studies in this \u001c",
      "eld. Engineering, health, agriculture, astron-\n",
      "omy, sports, cyber security, and education are among the\n",
      "many \u001c",
      "elds where machine learning and computer vision\n",
      "are used [6].\n",
      "A. MOTIVATION\n",
      "There is no systematic literature review (SLR) for machine\n",
      "learning styles used in computer vision focuses on method-\n",
      "ology, datasets, application areas, comparative analysis, and\n",
      "107294 VOLUME 10, 2022S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "FIGURE 2. 2015-2022 year-wise publication count of learning styles.\n",
      "future directions. The existing literature lacks a comprehen-\n",
      "sive survey focused on evolution of each ML style with\n",
      "its architecture, CV applications, research gaps and future\n",
      "directions.\n",
      "The table 1 and \u001c",
      "gure 4 shows how few papers have dealt\n",
      "with datasets. The same datasets are available; however, each\n",
      "one only has a speci\u001c",
      "c amount of data. Different machine\n",
      "learning styles are used in almost every application, such\n",
      "as Cyber security, Object detection, Spam detection, Health\n",
      "Care sector, Agriculture, etc. So, based on the above lit-\n",
      "erature, we suggested when and where to use a particular\n",
      "machine learning style. The main goal of this review is to\n",
      "highlight current strategies, datasets that are accessible, appli-\n",
      "cations, dif\u001c",
      "culties, and potential future directions of various\n",
      "machine learning approaches used in computer vision. In the\n",
      "last section this survey describes the current research gaps\n",
      "with the possible ML styles as solution and the future direc-\n",
      "tions in the \u001c",
      "eld of computer vision.\n",
      "B. CONTRIBUTION OF WORK\n",
      "The contributions of this comprehensive literature review are\n",
      "as follows:\u000fThe authors comprehensively review the literature on\n",
      "ML styles in computer vision, emphasizing method-\n",
      "ology, datasets, applications, associated problems, and\n",
      "potential future directions.\n",
      "\u000fThe authors discuss and investigate the ML approaches\n",
      "and methodologies used and how they revive the com-\n",
      "puter vision \u001c",
      "eld.\n",
      "\u000fThe authors also give a summary of various publicly\n",
      "accessible datasets that are used to support this \u001c",
      "eld of\n",
      "study.\n",
      "\u000fIn addition, the authors examine distinct application\n",
      "domains while assessing machine learning techniques'\n",
      "function.\n",
      "\u000fAuthors outline dif\u001c",
      "culties with various machine learn-\n",
      "ing approaches, such as datasets, the accuracy of existing\n",
      "systems, and processing high-quality data.\n",
      "C. PAPER ORGANIZATION\n",
      "To summarize, this study provides the following important\n",
      "contributions:\n",
      "1) This research aims at how different machine learning\n",
      "styles are used in computer vision, analyses its uses, and\n",
      "predicts future trends.\n",
      "VOLUME 10, 2022 107295S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "FIGURE 3. Outline of paper.\n",
      "2) Evolution and literature review of different machine\n",
      "learning styles used in various domains of computer vision.\n",
      "3) The study discovered brief overview of architecture,\n",
      "working, CV applications, datasets used, advantages and lim-\n",
      "itations of primary,hybrid and advanced ML styles.4) Recent research gaps identi\u001c",
      "ed and highlight the future\n",
      "directions.\n",
      "The rest of this article is organized as follows:\n",
      "Section 2 gives background knowledge in terms of Evolution\n",
      "of all ML styles. Section 3describes literature review in\n",
      "107296 VOLUME 10, 2022S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "FIGURE 4. AI in computer vision.\n",
      "terms of past eight year's publication count of papers in\n",
      "Scopus of each learning style and existing survey status\n",
      "of each ML style. Section 4 describes the introduction,framework, computer vision applications, datasets and tech-\n",
      "niques used with accuracy achieved of all machine learning\n",
      "styles. The comparative analysis of different ML styles,\n",
      "VOLUME 10, 2022 107297S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "research gaps identi\u001c",
      "ed with future directions discussed\n",
      "in Section 5.Section 6 gives the conclusion\n",
      "Results: results.\n",
      "Computer vision is important for the Internet of Things,\n",
      "Industrial Internet of Things, and human cognitive interfaces.\n",
      "Computer vision and machine learning techniques are used\n",
      "to identify and track complex human actions in multimedia\n",
      "streams. For the prediction and analysis task of data, there are\n",
      "three types of learning: supervised, unsupervised, and semi-\n",
      "supervised [2].\n",
      "The ability of computers to gather data, interpret it and\n",
      "make decisions based on past and present results is the aim\n",
      "of machine learning and computer vision. Computer vision\n",
      "is essential for the Internet of Things, Industrial Internet of\n",
      "Things, and human cognitive interfaces. Computer vision\n",
      "and machine learning techniques are used to identify and\n",
      "track complex human actions in multimedia streams. The\n",
      "image segmentation, localization & classi\u001c",
      "cation, and object\n",
      "detection are shown in the \u001c",
      "gure1. The authors have outlined\n",
      "the application areas of computer vision in the \u001c",
      "gure 4. They\n",
      "have listed which machine learning techniques and Python\n",
      "Libraries have been employed in each \u001c",
      "eld.\n",
      "An essential method of image processing that examines\n",
      "the contents of the image is segmentation. Image segmenta-\n",
      "tion can be used for pattern recognition, feature extraction,\n",
      "content-based image retrieval, etc. Image segmentation is an\n",
      "important process in most medical image analysis. K-means\n",
      "is a widely used clustering algorithm to partition data into k\n",
      "clusters. The K-means and fuzzy K-means clustering algo-\n",
      "rithms can be used to identify tumor cells in MR images\n",
      "that may show the characteristics of the tumor's severity,\n",
      "facilitating the necessary diagnosis and therapy. There are\n",
      "numbers of well-established algorithms for prediction and\n",
      "analysis such as supervised learning, un-supervised learning,\n",
      "and semi supervised learning. These methods use the machine\n",
      "learning algorithms such as support vector machine, KNN\n",
      "etc. Scipy, Scikit, OpenCV, Matplotlib and Keras are the\n",
      "popular are libraries used for image segmentation.For object detection previously sliding window, selective\n",
      "search and Kadane's algorithms were used but now most\n",
      "of the application areas uses deep learning algorithms like\n",
      "RCNN,YOLO,SSD for object detection in CV. The software\n",
      "libraries utilized in object detection for computer vision are\n",
      "Tensor Flow, ImageAI, GluonCV and YOLOv7. Convolution\n",
      "neural networks, recurrent neural networks, long short-term\n",
      "memories, gated recurrent units, and Bayesian networks are\n",
      "all used in traf\u001c",
      "c detection models. Sensors in intelligent\n",
      "settings collect data that is later analyzed and forecasted.\n",
      "One of the tasks the convolution neural network (CNN)\n",
      "successfully completes for successful object detection is\n",
      "feature extraction [3]. With a big collection of face pho-\n",
      "tos, a deep convolution neural network can recognize faces\n",
      "through supervised learning. Data annotation and labeling is\n",
      "the only problem in computer vision and machine learning\n",
      "applications. The support vector machines, neural networks,\n",
      "KNN and probabilistic graphical models machine learning\n",
      "paradigms for computer vision. A common classi\u001c",
      "cation\n",
      "technique is support vector machines (SVMs), a sub\u001c",
      "eld of\n",
      "supervised machine learning techniques. With a maximum\n",
      "margin separating two signi\u001c",
      "cant classifed classes, SVMs\n",
      "seek to locate a hyperplane [4]. Layered networks of con-\n",
      "nected processing nodes make up a neural network. A class of\n",
      "neural networks called convolution neural networks (CNNs)\n",
      "is utilized for image recognition and categorization. It has\n",
      "neurons that are wide, large, and deep. Due to widely avail-\n",
      "able datasets, GPUs, and regularization approaches, CNN has\n",
      "become more and more popular in recent years.\n",
      "The paper looks at a variety of machine learning applica-\n",
      "tions in computer vision. For instance, biological sciences\n",
      "include segmentation, feature extraction, pattern match-\n",
      "ing, visual model optimization, form representation, surface\n",
      "reconstruction, and modeling. Computer vision uses machine\n",
      "learning to evaluate data from images that detect cars and\n",
      "pedestrians, using images to analyze remote sensing data\n",
      "for geographic information systems, diagnose faults in rail-\n",
      "road ties automatically, identify different varieties of mango\n",
      "fruit based on size attributes, and extract graphical and tex-\n",
      "tual information from document images [5]. Detecting curb\n",
      "ramps in Google Street View, automatically detecting and\n",
      "identifying faces, machine vision, handwriting recognition,\n",
      "enhanced driving assistance systems, and behavioral mea-\n",
      "sures are some of the other techniques. Computer vision and\n",
      "machine learning are also used in the medical \u001c",
      "eld, espe-\n",
      "cially in nuclear medicine, endoscopy, angiography, mag-\n",
      "netic resonance, ultrasound, and microscopy, according to\n",
      "studies in this \u001c",
      "eld. Engineering, health, agriculture, astron-\n",
      "omy, sports, cyber security, and education are among the\n",
      "many \u001c",
      "elds where machine learning and computer vision\n",
      "are used [6].\n",
      "A. MOTIVATION\n",
      "There is no systematic literature review (SLR) for machine\n",
      "learning styles used in computer vision focuses on method-\n",
      "ology, datasets, application areas, comparative analysis, and\n",
      "107294 VOLUME 10, 2022S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "FIGURE 2. 2015-2022 year-wise publication count of learning styles.\n",
      "future directions. The existing literature lacks a comprehen-\n",
      "sive survey focused on evolution of each ML style with\n",
      "its architecture, CV applications, research gaps and future\n",
      "directions.\n",
      "The table 1 and \u001c",
      "gure 4 shows how few papers have dealt\n",
      "with datasets. The same datasets are available; however, each\n",
      "one only has a speci\u001c",
      "c amount of data. Different machine\n",
      "learning styles are used in almost every application, such\n",
      "as Cyber security, Object detection, Spam detection, Health\n",
      "Care sector, Agriculture, etc. So, based on the above lit-\n",
      "erature, we suggested when and where to use a particular\n",
      "machine learning style. The main goal of this review is to\n",
      "highlight current strategies, datasets that are accessible, appli-\n",
      "cations, dif\u001c",
      "culties, and potential future directions of various\n",
      "machine learning approaches used in computer vision. In the\n",
      "last section this survey describes the current research gaps\n",
      "with the possible ML styles as solution and the future direc-\n",
      "tions in the \u001c",
      "eld of computer vision.\n",
      "B. CONTRIBUTION OF WORK\n",
      "The contributions of this comprehensive literature review are\n",
      "as follows:\u000fThe authors comprehensively review the literature on\n",
      "ML styles in computer vision, emphasizing method-\n",
      "ology, datasets, applications, associated problems, and\n",
      "potential future directions.\n",
      "\u000fThe authors discuss and investigate the ML approaches\n",
      "and methodologies used and how they revive the com-\n",
      "puter vision \u001c",
      "eld.\n",
      "\u000fThe authors also give a summary of various publicly\n",
      "accessible datasets that are used to support this \u001c",
      "eld of\n",
      "study.\n",
      "\u000fIn addition, the authors examine distinct application\n",
      "domains while assessing machine learning techniques'\n",
      "function.\n",
      "\u000fAuthors outline dif\u001c",
      "culties with various machine learn-\n",
      "ing approaches, such as datasets, the accuracy of existing\n",
      "systems, and processing high-quality data.\n",
      "C. PAPER ORGANIZATION\n",
      "To summarize, this study provides the following important\n",
      "contributions:\n",
      "1) This research aims at how different machine learning\n",
      "styles are used in computer vision, analyses its uses, and\n",
      "predicts future trends.\n",
      "VOLUME 10, 2022 107295S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "FIGURE 3. Outline of paper.\n",
      "2) Evolution and literature review of different machine\n",
      "learning styles used in various domains of computer vision.\n",
      "3) The study discovered brief overview of architecture,\n",
      "working, CV applications, datasets used, advantages and lim-\n",
      "itations of primary,hybrid and advanced ML styles.4) Recent research gaps identi\u001c",
      "ed and highlight the future\n",
      "directions.\n",
      "The rest of this article is organized as follows:\n",
      "Section 2 gives background knowledge in terms of Evolution\n",
      "of all ML styles. Section 3describes literature review in\n",
      "107296 VOLUME 10, 2022S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "FIGURE 4. AI in computer vision.\n",
      "terms of past eight year's publication count of papers in\n",
      "Scopus of each learning style and existing survey status\n",
      "of each ML style. Section 4 describes the introduction,framework, computer vision applications, datasets and tech-\n",
      "niques used with accuracy achieved of all machine learning\n",
      "styles. The comparative analysis of different ML styles,\n",
      "VOLUME 10, 2022 107297S. V. Mahadevkar et al.: Review on Machine Learning Styles in Computer Vision\u0016Techniques and Future Directions\n",
      "research gaps identi\u001c",
      "ed with future directions discussed\n",
      "in Section 5.Section 6 gives the conclusion\n",
      "\n",
      "Extracted Information for C:/Users/pruth/AppData/Roaming/Jupyter/runtime/MLpapre2.pdf:\n",
      "Authors: ['Abdelaaziz Hessane', 'Ahmed El', 'Badraddine Aghoutane', 'Fatima Amounas', 'Hessane', 'Ahmed El Yousseﬁ', 'Yousef Farhaoui', 'Fig', 'Accuracy', 'Recall', 'Fig', 'Jadhav', 'Khan', 'Aqel\\net', 'Lu', 'strawberry', 'Kumar', 'Adaboost', 'neuro-fuzzy', 'Rao', 'Kulkarni[15]to', 'Alaa et', 'Al-Shalout', 'Fig', 'Fig', 'Fig', 'Fig', 'Fig', 'Fig', 'Harlick', 'space[24', 'measures[26', 'Hessane', 'irrelevant[27', 'Eq', 'C.\\n', 'task[30', 'similarity[31]', 'boosting[33', 'Accuracy', 'Eq', 'Recall', 'PrecisionCRecall(15', 'Fig', 'Abdelaaziz Hessane', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSV\\n', 'Fig', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSV\\n', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSV\\n', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSVGLCM', 'onlyGLCM\\n+HSV\\n', '0.96\\nStage', 'Accuracy', 'palm\\nWSD', 'ﬁeld', 'J. M.\\nAl-Khayri', 'S. M. Jain', 'Johnson', 'R. Meziani', 'M. A. Mazri', 'M. A. Chitt', 'R.\\nBouamri', 'F. Jaiti', 'Majhoul', 'theAbdelaaziz Hessane', 'K. Golhani', 'R. R. Shamshiri', 'G. Vadamalai', 'I. U. Haq', 'F. Hafeez', 'A. Ali', 'M. Farooq', 'M.\\nSaleem', 'A. Ghaffar', 'Stud', 'S. Patil', 'Conf', 'M. Ali', 'M. Ahmad', 'N. Zaman', 'E. S. Jaha', 'Intell', 'Soft Comput', 'S. Al-Zubi', 'Jararweh', 'Cluster Comput', 'J. Sun', 'N. Yang', 'X. H. Wu', 'X. Zhou', 'Spectrosc', 'Shao', 'X. Li', 'Sci', 'P. Leela Rani', 'Guru Gokul', 'R. Kannadasan', 'M. H. Alsharif', 'A. Jahid', 'M. A. Khan', 'Categorizing', 'K. Chang', 'T. Nguyen-Quang', 'P.\\nRavichandran', 'strawberry', 'K. Sharma', 'A. Singh', 'M. K. Sharma', 'V', 'S. Dhaka', 'N.\\nDey', 'J. Manuel', 'R. S. Tavares', 'C. Raman', 'S. Mantri', 'Plant', 'Conf', 'S. B. Kulkarni', 'Int', 'J. Electr', 'K. Waleed', 'M. Samir', 'M. Tarek', 'M. A. Salam', 'J. Adv', 'J. A. Mahar', 'M. A. Razzaq', 'S. H. Gill', 'Bahawalpur', 'G. Hu', 'Front', 'Plant Sci.', 'S. Fekri-Ershad', 'B. Sebastian, A. Unnikrishnan', 'K. Balakrishnan', 'Int', 'J. Comput', 'Technol', 'I. H. Dinstein', 'Man', 'C. A. Harlow', 'Mach', 'Intell', 'https://ww2', 'J. A. Ojo, A. O. Amole', 'A. O.\\nDurodola', 'J.\\nComput', 'Trends Technol', 'Conf', 'p.\\n012024', 'Dev', 'Mater', 'A. B. A. Hassanat', 'O. Lasassmeh', 'H. S. E. Salman', 'B. S.\\nPrasath', 'E. J. Kusuma', 'C. A. Sari', 'D. R. I. M. Setiadi', 'R. Mumtaz', 'I. U. Haq', 'M. Hafeez', 'A.\\nShaukat', 'Z. Mahmood', 'X. Ying', 'J.\\nPhys', 'Conf', 'Ahmed El Yousseﬁ', 'Yousef Farhaoui', 'Inderscience', 'Badraddine Aghoutane', 'Sidi Mohamed Ben Abdellah University', 'Fatima Amounas']\n",
      "Publication Year: 2096\n",
      "Methods: methods, namely, support vector machine (SVM) and k-nearest neighbors (KNN), and ensemble\n",
      "learning methods such as random forest (RF) and light gradient boosting machine (LightGBM). The ML models were\n",
      "trained and evaluated using two datasets: the ﬁrst is composed of the extracted GLCM features only, and the second\n",
      "combines GLCM and HSV descriptors. The results\n",
      "Results: results indicate that SVM classiﬁer outperformed on combined GLCM\n",
      "and HSV features with an accuracy of 98.29%. The proposed framework could be beneﬁcial to the oasis agricultural\n",
      "community in terms of early detection of date palm white scale disease (DPWSD) and assisting in the adoption of\n",
      "preventive measures to protect both date palm trees and crop yield.\n",
      "Key words: precision agriculture; machine learning; ensemble learning; feature extraction; date palm; diseases\n",
      "1 Introduction\n",
      "The date palm is a crop with signiﬁcant socioeconomic\n",
      "and ecological importance in Morocco[1]. The latter\n",
      "has been prioritized by Morocco’s Green Plan (MGP)\n",
      "\u000fAbdelaaziz Hessane, Ahmed El Yousseﬁ, and Yousef Farhaoui are with the STI Laboratory, IDMS, Faculty of Sciences and Techniques,\n",
      "Moulay Ismail University of Meknes, Errachidia 52000, Morocco. E-mail: a.hessane@edu.umi.ac.ma; ah.elyousseﬁ@edu.umi.ac.ma;\n",
      "y.farhaoui@fste.umi.ac.ma.\n",
      "\u000fBadraddine Aghoutane is with the IA Laboratory, Department of Computer Science, Faculty of Sciences, Moulay Ismail University of\n",
      "Meknes, Meknes 50070, Morocco. E-mail: b.aghoutane@umi.ac.ma.\n",
      "\u000fFatima Amounas is with RO.AL&I Group, Computer Sciences Department, Faculty of Sciences and Techniques, Moulay Ismail\n",
      "University of Meknes, Errachidia 52000, Morocco. E-mail: f amounas@yahoo.fr.\n",
      "*To whom correspondence should be addressed.\n",
      "Manuscript received: 2022-06-18; accepted: 2022-07-06through promoting and helping farmers in growing these\n",
      "trees, which account for around 60% of agricultural\n",
      "revenue in oasis and employ over two million\n",
      "people[2]. Plant disease detection and classiﬁcation264 Big Data Mining and Analytics, September 2023, 6(3): 263–272\n",
      "is a key factor of precision farming[3]. Identifying the\n",
      "diseases that affect date palms and determining the\n",
      "degree of infestation is one of the challenges facing the\n",
      "farmer, especially when the symptoms are very similar,\n",
      "which makes choosing the appropriate practice and\n",
      "treatment difﬁcult and, in many cases, wrong. Palm date\n",
      "scale is sap-sucking pests that feed and form colonies on\n",
      "palm leaﬂets. The palm date scale is considered a minor\n",
      "pest of low agricultural signiﬁcance[4]. Still, in very high\n",
      "infestation levels, the palm date scale (see Fig. 1) can\n",
      "cause tissue necrosis which can cause harmful damages\n",
      "from negatively affecting the quality of produced fruits\n",
      "to the death of the tree[5]. The choice to use chemical\n",
      "treatment or not is determined by the degree of the\n",
      "infestation. This is considered a time and labor expensive\n",
      "task as visual control needs to be done regularly by\n",
      "farmers or experts.\n",
      "The aim of this study is to evaluate the effectiveness of\n",
      "machine learning methods in identifying and staging of\n",
      "the white scale disease (WSD) within the date palms.\n",
      "For that reason, feature extraction techniques were\n",
      "performed on a multiclass image dataset to produce two\n",
      "types of descriptors, namely gray level co-occurrence\n",
      "matrix (GLCM) and hue, saturation, and value (HSV)\n",
      "color moments. The retrieved characteristics were then\n",
      "used to train various classical and ensemble-based\n",
      "machine learning (ML) models which are multiclass\n",
      "support vector machine (SVM), k-nearest neighbors\n",
      "(KNN), random forest (RF), and light gradient boosting\n",
      "machine (LightGBM). To measure the performance\n",
      "of the different models, Accuracy, Precision, Recall,\n",
      "and F1-score were calculated. This suggested solution\n",
      "would assist date palm growers and owners in protecting\n",
      "their crops and increasing productivity by utilizing\n",
      "machine learning techniques for accurate classiﬁcation\n",
      "and identiﬁcation of WSD infestation degrees.\n",
      "The main contributions of this work are as follow.\n",
      "\u000fTo examine the potential for WSD detection and\n",
      "Fig. 1 Example of a palm tree infected by white scale.infestation degree classiﬁcation using classical and\n",
      "ensemble-based machine learning methods.\n",
      "\u000fTo explore two features (GLCM-based features and\n",
      "HSV Color Moments) to ﬁnd the most effective for WSD\n",
      "stage-wise classiﬁcation.\n",
      "\u000fTo conduct a set of experiments to analyze the effect\n",
      "of using only texture feature versus the use of combined\n",
      "color and texture patterns in recognizing and classifying\n",
      "WSD.\n",
      "\u000fTo measure the classiﬁcation performance of each\n",
      "model using various stage-wise metrics.\n",
      "This paper is structured as follows. In Section 2, we\n",
      "present a brief literature review of studies conducted\n",
      "to identify and diagnose plant diseases using feature\n",
      "extraction and machine learning techniques. Section 3\n",
      "describes the proposed framework. Finally, in Section 4,\n",
      "we report the obtained results, and in Section 5, we\n",
      "discuss the future implications of our work.\n",
      "2 Related Work\n",
      "Over the recent years, numerous studies have been\n",
      "undertaken to identify and diagnosis plant diseases\n",
      "by utilizing feature extraction in conjunction with\n",
      "machine learning approaches. A framework based on\n",
      "multiclass support vector machines was described by\n",
      "Jadhav et al.[6]for identifying soybean disease. To\n",
      "begin with, infected regions were extracted using k-\n",
      "means clustering technique on images of healthy and\n",
      "diseased leaves, and then GLCM-based features and\n",
      "RGB color-based statistical properties were merged\n",
      "and used as features for the SVM classiﬁer which\n",
      "outperformed with an accuracy of 90.20%. Khan et\n",
      "al.[7]proposed the use of a deep neural network,\n",
      "especially the back propagation neural network (BPNN)\n",
      "to identify and classify walnut fungal infections. Before\n",
      "extracting relevant features using color moments and\n",
      "GLCM, preprocessing techniques such as downsizing,\n",
      "intensity improvement, and histogram equalization have\n",
      "been used. The performance of the BPNN classiﬁer\n",
      "was 95.3% accurate. The extreme learning machine\n",
      "(ELM) was employed to perform the classiﬁcation\n",
      "of plant diseases[8–10]. The proposed method by Aqel\n",
      "et al.[8]begins by establishing the regions of interest\n",
      "(RoI) based on the k-means method. As a result,\n",
      "their method outperformed by an accuracy of 94%.\n",
      "Hyperspectral images based features were used in\n",
      "Refs. [9, 10]. As proposed by Lu et al.[9], ten GLCM-\n",
      "based features merged with more than 900 local binary\n",
      "patterns (LBP)-based features were used to train anAbdelaaziz Hessane et al.: A Machine Learning Based Framework for a Stage-Wise Classiﬁcation of Date Palm ::: 265\n",
      "ELM classiﬁer. Their approach achieved an accuracy\n",
      "of approximately 92.3%. Devi et al.[11]proposed the\n",
      "use of synthetical features to improve the classiﬁcation\n",
      "accuracy of plant diseases. A hybrid learning model\n",
      "that incorporates both GLCM-based and synthetically\n",
      "generated features as an input of a convolutional neural\n",
      "network (CNN) was used. The performance of the CNN\n",
      "was then compared to that of the SVM and the ELM\n",
      "algorithms, and it was determined that CNN achieved\n",
      "the highest accuracy of 92.6%. Shin et al.[12]compared\n",
      "two machine learning models (artiﬁcial neural network\n",
      "(ANN) and SVM) as well as three feature extraction\n",
      "algorithms (histogram of oriented gradient (HOG),\n",
      "speedup robust features (SURF), and GLCM) to detect\n",
      "powdery mildew on strawberry leaves. Experiments\n",
      "reveal that SURF+ANN performs the best, with an\n",
      "accuracy of 90.38%. To perform plant disease detection\n",
      "and classiﬁcation, Kumar et al.[13]suggest the Adaboost\n",
      "algorithm in conjunction with k-means clustering and\n",
      "Otsu’s thresholding for RoI detection. After that,\n",
      "features were computed using GLCM and the proposed\n",
      "classiﬁer outperformed with an accuracy of 85%. As\n",
      "reported by Panchal et al.[14], random forest method is\n",
      "used to classify infected part of the leaves, the latter\n",
      "is detected using a combination of k-means clustering\n",
      "algorithm and HSV dependent classiﬁcation. The\n",
      "proposed framework reached a remarkable accuracy of\n",
      "98%. Other ML methods like neuro-fuzzy logic classiﬁer\n",
      "was proposed by Rao and Kulkarni[15]to conduct the\n",
      "classiﬁcation of plant disease based on the combination\n",
      "of multiple features such as GLCM, complex gabor ﬁlter,\n",
      "curvelet and image moments.\n",
      "Despite recent advances in technology, little research\n",
      "is being conducted in the ﬁeld of early identiﬁcation and\n",
      "classiﬁcation of date palm disease. Alaa et al.[16]reported\n",
      "that the classiﬁcation of some diseases like blight spots\n",
      "and leaf spots is possible by using CNN. The proposed\n",
      "system has reached an accuracy of 97.9%. Magsi et\n",
      "al.[17]demonstrated that it is possible to diagnose sudden\n",
      "decline syndrome illness utilizing ML and feature\n",
      "extraction approaches. They suggested a three-steps\n",
      "method based on image preprocessing, feature extraction\n",
      "using both color and texture descriptors, and a CNN-\n",
      "based classiﬁcation method. According to Al-Shalout\n",
      "and Mansour[18], CNN exhibits encouraging results in\n",
      "the identiﬁcation and classiﬁcation of date palm diseases.\n",
      "However, to execute identiﬁcation or classiﬁcation\n",
      "tasks, the deep learning approach necessitates the use\n",
      "of large and well-annotated datasets, which requiresconsiderable effort and attention. Therfore, machine\n",
      "learning combined with feature extraction technique may\n",
      "be adopted as a resort to perform the sub-mentioned\n",
      "tasks.\n",
      "3 Experimental Methodology\n",
      "We propose a WSD stage-wise classiﬁcation system\n",
      "based on feature extraction and two types of machine\n",
      "learning algorithms. The architecture of the proposed\n",
      "system is shown in Fig. 2, which consists of the three\n",
      "major phases including data preprocessing, feature\n",
      "extraction, and models training and performance\n",
      "evaluation. In what follow, we will describe each of\n",
      "these phases.\n",
      "3.1 Dataset\n",
      "The dataset utilized in the context of this work is a public\n",
      "dataset[19]composed of more than 2000 labeled date\n",
      "palm leaﬂet images. This dataset presents three main\n",
      "classes which are (1) healthy, (2) brown spots disease,\n",
      "and (3) white scale disease. Since we are investigating\n",
      "WSD, only the images from the two classes (1) and (3)\n",
      "were used. The latter comprises pictures of leaﬂets that\n",
      "have been infested at three different stages. Figures 3\n",
      "Fig. 2 System architecture.\n",
      "Fig. 3 Initial number of samples per infestation degree.266 Big Data Mining and Analytics, September 2023, 6(3): 263–272\n",
      "and 4 illustrate the number of WSD-infected leaﬂets per\n",
      "stage and some representative samples from each class,\n",
      "respectively. Finally, the dataset is divided into a training\n",
      "set which represents 80% of the entire dataset, and the\n",
      "remaining 20% is used for testing purposes.\n",
      "3.2 Data preprocessing\n",
      "The two difﬁculties we faced are as follows. (1) The\n",
      "classes in the dataset are imbalanced. Given the number\n",
      "of images in the class of healthy leaﬂets, the latter is\n",
      "dominant, accounting for around 56% of the dataset as\n",
      "illustrated in Fig. 5. (2) The very low sample size per\n",
      "class which will have a signiﬁcant effect on the learning\n",
      "process. To address the sub mentioned issues, we choose\n",
      "to use data augmentation techniques[20]on both majority\n",
      "and minority classes.\n",
      "We performed numerous modiﬁcations on the images,\n",
      "such as zooming, rotation, horizontal ﬂipping, width\n",
      "and height shifting. Finally, we created a set of\n",
      "augmented images by combining these transformations.\n",
      "Table 1 summarizes the distribution of the samples\n",
      "(a) Healthy leaﬂet\n",
      " (b) Low infestation degree\n",
      " (c) Medium infestation degree\n",
      "(d) High infestation degree\n",
      "Fig. 4 Samples of healthy and infected leaﬂets.\n",
      "Fig. 5 Distribution of images per class.\n",
      "Table 1 Distribution of samples in the training set and\n",
      "testing set.\n",
      "Dataset HealthyInfected by white scale diseaseTotalStage 1 Stage 2 Stage 3\n",
      "Training set 1258 1219 1264 1197 4938\n",
      "Testing set 340 336 312 301 1289per class in the training set and the testing set. Other\n",
      "preprocessings such as down sampling, color mode\n",
      "conversions from RGB to grayscale and from RGB to\n",
      "HSV , and normalization were performed to prepare the\n",
      "dataset for the feature extraction phase.\n",
      "3.3 Feature’s extraction\n",
      "In image processing, feature extraction means the\n",
      "quantiﬁcation of certain features as opposed to utilizing\n",
      "all of the information at the pixel level. The fundamental\n",
      "objective is to decrease the dimensions by generating a\n",
      "collection of expressive values characterizing the entire\n",
      "image. Consequently, computational time and used\n",
      "memory will be optimized. Therefore, this technique is\n",
      "widely utilized for classiﬁcation, object detection, and\n",
      "recognition tasks[21]. In the context of this study, two\n",
      "descriptors were examined. The ﬁrst one is a set of 80\n",
      "GLCM-based texture features, and the second is the\n",
      "combination of nine statistical HSV color moment based\n",
      "features and the already extracted GLCM-based features.\n",
      "More details about the process of feature extraction are\n",
      "tackled in Sections 3.3.1 and 3.3.2.\n",
      "3.3.1 Gray level co-occurrence matrix (GLCM)\n",
      "To recognize the regions of interest (RoI), the analysis\n",
      "of image textures proved to be efﬁcient[22]. One way\n",
      "to extract the texture properties from an image is to\n",
      "calculate second order statistical values introduced by\n",
      "Harlick et al.[23]which requires the study of the relation\n",
      "between two pairs of pixels in terms of space[24]. In\n",
      "the context of this work, we decided to investigate the\n",
      "potential of gray level co-occurrence matrix (GLCM)\n",
      "in characterizing textures presented in healthy and\n",
      "WSD infected leaﬂets images. We did calculate the\n",
      "ﬁve statistical measures, namely, energy, correlation,\n",
      "dissimilarity, homogeneity, and contrast, proposed by\n",
      "Conners and Harlow[25]from the GLCM and used them\n",
      "as texture features. The chosen statistical measures[26]\n",
      "are described bellow. To deﬁne a sufﬁcient variety\n",
      "of spatial relations between the image’s pixels, we\n",
      "suggested the use of four different distances d(i.e., 1,\n",
      "3, 6, and 9) and four different orientations \u0012(i.e., 0,\n",
      " /4, /2, and 3 /4). For each pair ( d,\u0012), the already\n",
      "mentioned statistical measures were computed. As a\n",
      "result, an 80 GLCM-based texture features vector is\n",
      "produced. The choice of various distances is justiﬁed\n",
      "by the fact that this value is critical for the image\n",
      "classiﬁcation task. To incorporate the texture patterns,\n",
      "the distance value must be large enough. At the same\n",
      "time, it must be small enough to maintain the localAbdelaaziz Hessane et al.: A Machine Learning Based Framework for a Stage-Wise Classiﬁcation of Date Palm ::: 267\n",
      "characteristic of spatial dependency[24].\n",
      "In what follows, Pi;jrepresents the element ( i;j) of\n",
      "the normalized symmetrical GLCM, Nis the number\n",
      "of the gray levels in the image, \u0016represents the GLCM\n",
      "mean calculated as shown in Eq. (1), and \u001b2is the\n",
      "GLCM intensities variance computed using the Eq. (2).\n",
      "\u0016DN\u00001X\n",
      "i;jD0iPi;j (1)\n",
      "\u001b2DN\u00001X\n",
      "i;jD0Pi;j.i\u0000\u0016/2(2)\n",
      "Energy indicates the grey level homogeneity between\n",
      "the pixels of an image: if the intensities of the grey\n",
      "level in adjacent pixels (pairs) are similar, the energy\n",
      "is low; otherwise, it is high[24]. It can be computed\n",
      "using the Eq. (3). Correlation measures the linearity and\n",
      "the predictability between a pair of pixels. Signiﬁcant\n",
      "and non signiﬁcant values mean the existence and\n",
      "nonexistence of this relationship, respectively. Equation\n",
      "(4) is used to calculate this measure. The dissimilarity\n",
      "is used to interpret the distance between a pair of\n",
      "pixels[27]. Equation (5) demonstrates how this measure\n",
      "is calculated.\n",
      "EnergyDN\u00001X\n",
      "i;jD0\u0000\n",
      "Pi;j\u00012(3)\n",
      "CorrelationDN\u00001X\n",
      "i;jD0Pi;j.i\u0000\u0016/.j\u0000\u0016/\n",
      "\u001b2(4)\n",
      "DissimilarityDN\u00001X\n",
      "i;jD0ji\u0000jjPi;j (5)\n",
      "Homogeneity quantiﬁes how near the elements\n",
      "distribution in the GLCM is to its diagonal[27]. Finally,\n",
      "the contrast measure represents the intensity between\n",
      "adjacent pixels. The inexistence of variation means that\n",
      "the contrast is irrelevant[27]. Homogeneity and contrast\n",
      "values are calculated using Eqs. (6) and (7), respectively.\n",
      "HomogeneityDN\u00001X\n",
      "i;jD01\n",
      "1Cji\u0000jj2Pi;j (6)\n",
      "ContrastDN\u00001X\n",
      "i;jD0ji\u0000jj2Pi;j (7)\n",
      "3.3.2 Combination of texture-based and color-\n",
      "based features\n",
      "HSV (i.e., hue, saturation, and value) is a color model\n",
      "that is believed to be an alternative to the RGB color\n",
      "representation. HSV is more consistent with the wayhuman vision processes colors. It shows enhanced color\n",
      "abstraction by differentiating the saturation and the\n",
      "value channels[28]. Color moments are probabilistic\n",
      "measurements that describe the distribution of an\n",
      "image’s color channels[28]. In this research, we opted\n",
      "for the extraction of three statistical measures for each\n",
      "channel (i.e., mean, standard deviation, and skewness),\n",
      "yielding a total of nine color-based features. The used\n",
      "measures are detailed bellow.\n",
      "\u000fMean. It calculates the average of pixel intensities\n",
      "in a color channel, it can be computed using Eq. (8).\n",
      "\u0016cD1\n",
      "N0NX\n",
      "i;jD1Ci;j (8)\n",
      "\u000fStandard deviation (SD). It measures the deviations\n",
      "between each observation and the mean. Equation (9) is\n",
      "used to compute the SD of a given channel C.\n",
      "\u001bcD0\n",
      "@1\n",
      "N0NX\n",
      "i;jD1\u0000\n",
      "Ci;j\u0000\u0016c\u000121\n",
      "A1\n",
      "2\n",
      "(9)\n",
      "\u000fSkewness. It calculates the symmetry of a color\n",
      "channel distribution. Equation (10) demonstrates how\n",
      "this measure is computed.\n",
      "scD0\n",
      "@1\n",
      "N0NX\n",
      "i;jD1\u0000\n",
      "Ci;j\u0000\u0016c\u000131\n",
      "A1\n",
      "3\n",
      "(10)\n",
      "whereCi;jrepresents the value of pixel at the position\n",
      ".i;j/ regarding the channel represented by C, whereas\n",
      "N0is referring to the total number of pixels.\n",
      "The obtained color-based characteristics of the image\n",
      "are represented by the vector given in Eq. (11). This set\n",
      "of features was combined with extracted GLCM features\n",
      "to form a vector that represents the healthy and infected\n",
      "date palm leaﬂets.\n",
      "FcolorsD\u0016H;\u001bH;sH;\u0016S;\u001bS;sS;\u0016V;\u001bV;sV(11)\n",
      "3.4 Machine learning models\n",
      "Machine learning (ML) is a subset of artiﬁcial\n",
      "intelligence (AI) that enables computers to automatically\n",
      "learn and improve with experience[29]. To fulﬁll\n",
      "this purpose, three main approaches are proposed,\n",
      "namely, supervised learning, unsupervised learning, and\n",
      "reinforcement learning. In supervised learning, the\n",
      "learning process is based on previous examples: models\n",
      "are trained using labeled dataset (i.e., each input is\n",
      "paired with an output), during which the model acquires\n",
      "knowledge about the various types of data. After\n",
      "training, the model is evaluated using a portion of the\n",
      "training set and then used to perform either a regression268 Big Data Mining and Analytics, September 2023, 6(3): 263–272\n",
      "or a classiﬁcation task[30]. To apply appropriate WSD\n",
      "degree of infestation classiﬁcation task, we have trained\n",
      "and evaluated several ML models, namely, classical\n",
      "ML models like SVM and CNN, and ensemble-based\n",
      "learning models such as random forest and LightGBM.\n",
      "3.4.1 Supervised classical ML algorithms\n",
      "In the context of this study, two supervised machine\n",
      "learning models were investigated, namely, multiclass\n",
      "SVM and KNN. SVM uses hyperplanes to separate data\n",
      "into several classes whose boundary is as far as possible\n",
      "from the data points (i.e., maximum margin)[28]. KNN\n",
      "algorithm classiﬁcation approach is based on learning\n",
      "data from neighbors (i.e., closet objects). To classify an\n",
      "unseen object, KNN classiﬁer calculates similarity[31]\n",
      "between learned patterns and test ones in a predeﬁned\n",
      "rangek[32].\n",
      "3.4.2 Ensemble learning algorithms\n",
      "When multiple models, like classiﬁers, are\n",
      "systematically generated and merged in order to\n",
      "tackle a speciﬁc computational task, this is referred to as\n",
      "ensemble learning, this can be done by adopting various\n",
      "strategies such as bagging and boosting[33]. Random\n",
      "forest (RF) is a bagging technique that generates a\n",
      "collection of decision trees from a randomly chosen\n",
      "subset of the training set, then it aggregates the votes\n",
      "(i.e., majority voting) from the various decision trees\n",
      "to determine the ﬁnal prediction[30]. LightGBM is a\n",
      "decision tree based gradient boosting framework. The\n",
      "classiﬁcation task becomes quicker while maintaining\n",
      "high accuracy thanks to the integration of two techniques:\n",
      "exclusive feature bundling (EFB) and gradient-based\n",
      "one side sampling (GOSS)[34].\n",
      "3.4.3 Model reliability and ﬁnetuning\n",
      "To avoid the overﬁtting[35]problem, and to assess\n",
      "the effectiveness and the reliability of the different\n",
      "ML models, we opted for a ﬁve-fold cross validation\n",
      "technique and a hyperparameters ﬁnetuning process to\n",
      "ﬁnd the optimal hyperparameters which were applied\n",
      "during the training phase of each model.\n",
      "3.4.4 Evaluation metrics\n",
      "Accuracy, Precision, Recall, F1-score, and confusion\n",
      "matrix are the evaluation metrics chosen to asses the\n",
      "ML models performance. For a given class, accuracy is\n",
      "deﬁned as the proportion of well classiﬁed samples out\n",
      "of the total number of samples in that class. This metric\n",
      "is calculated using Eq. (12).\n",
      "AccuracyDTPCTN\n",
      "TPCFPCTNCFN\u0002100% (12)True positives (TP) mean that the model predicted\n",
      "the positive class correctly. In the same way, the true\n",
      "negatives (TN) indicate that the model has correctly\n",
      "predicted that the class is negative. In contrast, a false\n",
      "positive (FP) means that the model mispredicts the\n",
      "positive class. And a false negative (FN) means that\n",
      "the model wrongly predicts that the class is negative.\n",
      "Precision, Recall, and F1-score are calculated using\n",
      "Eqs. (13)–(15), respectively.\n",
      "PrecisionDTP\n",
      "TPCFP(13)\n",
      "RecallDTP\n",
      "TPCFN(14)\n",
      "F1-scoreD2\u0002Precision\u0002Recall\n",
      "PrecisionCRecall(15)\n",
      "In the context of this work, class-wise metrics were\n",
      "computed, and arithmetic mean of individual class\n",
      "(macro average) were calculated for each of the already\n",
      "mentioned metrics (i.e., Recall, Precision, and F1-score).\n",
      "Finally, confusion matrices were used to analyze and\n",
      "interpret the performance of the different investigated\n",
      "ML models.\n",
      "4 Result\n",
      "In this study, we proposed a framework for automatically\n",
      "classifying WSD into its three degrees of infestation. For\n",
      "this purpose, machine learning models are applied on\n",
      "two datasets which are GLCM-based texture features\n",
      "and combined GLCM and HSV color moments features.\n",
      "To fulﬁll the objectives, four ML models were applied\n",
      "including SVM, KNN, RF, and LightGBM. To assess\n",
      "the performance of each algorithm, several stage-wise\n",
      "metrics are used. Table 2 presents the performance of\n",
      "SVM classiﬁer. An accuracy of 97.83% was obtained\n",
      "when using GLCM-based texture features only and\n",
      "98.29% on combined texture and color GLCM+HSV\n",
      "features which is mainly due to the detailed statistical\n",
      "information provided by the chosen features. The\n",
      "incorporation of HSV features has slightly improved\n",
      "the accuracy by approximatively 0.5%.\n",
      "When looking at the confusion matrices of the SVM\n",
      "classiﬁer (Fig. 6), it is evident that all susceptible\n",
      "images are correctly classiﬁed when using combined\n",
      "GLCM+HSV features. However, there are some ﬁrst\n",
      "level infestation samples (class 1) that are misclassiﬁed\n",
      "as healthy (class 0) or as a second level infestation (class\n",
      "3). This is mainly due to their similarity in terms of the\n",
      "diseases visual patterns. However, level 3 infestation\n",
      "samples are successfully classiﬁed (100% of accuracy)\n",
      "because of their distinctive color and texture properties.Abdelaaziz Hessane et al.: A Machine Learning Based Framework for a Stage-Wise Classiﬁcation of Date Palm ::: 269\n",
      "Table 2 Performance comparison of SVM classiﬁcation on\n",
      "GLCM only and GLCM+HSV features.\n",
      "ClassPrecision Recall F1-score\n",
      "GLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSV\n",
      "Healthy 0.99 0.98 0.98 0.99 0.99 0.99\n",
      "White\n",
      "scale\n",
      "diseaseStage 1 0.96 0.98 0.96 0.96 0.96 0.97\n",
      "Stage 2 0.96 0.97 0.98 0.98 0.97 0.98\n",
      "Stage 3 1.00 1.00 1.00 1.00 1.00 1.00\n",
      "Macro average 0.98 0.98 0.98 0.98 0.98 0.98\n",
      "(a) GLCM only\n",
      " (b) GLCM+HSV\n",
      "Fig. 6 Confusion matrices of SVM classiﬁer. 0–3 indicate\n",
      "healthy, low infestation degree, medium infestation degree,\n",
      "and high infestation degree, respectively. The color metric\n",
      "scale represents the number of prediction in the confusion\n",
      "matrices.\n",
      "Similarly, Table 3 summarizes the KNN performance\n",
      "using the same class-wise metrics. KNN classiﬁer\n",
      "achieves 94.49% of accuracy on GLCM features dataset\n",
      "and 96.90% of accuracy when using the GLCM+HSV-\n",
      "based features. The introduction of color descriptors\n",
      "improves the accuracy by 2.55%.\n",
      "KNN classiﬁcation confusion matrices are shown\n",
      "on Fig. 7 where the distribution of well-classiﬁed\n",
      "and misclassiﬁed images is illustrated. Again, samples\n",
      "Table 3 Performance comparison of KNN classiﬁcation on\n",
      "GLCM only and GLCM+HSV features.\n",
      "ClassPrecision Recall F1-score\n",
      "GLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSV\n",
      "Healthy 0.99 1.00 0.92 0.97 0.95 0.98\n",
      "White\n",
      "scale\n",
      "diseaseStage 1 0.92 0.94 0.90 0.95 0.91 0.94\n",
      "Stage 2 0.92 0.95 0.96 0.96 0.94 0.96\n",
      "Stage 3 0.96 1.00 1.00 1.00 0.98 1.00\n",
      "Macro average 0.95 0.97 0.95 0.97 0.95 0.97\n",
      "(a) GLCM only\n",
      " (b) GLCM+HSV\n",
      "Fig. 7 Confusion matrices of KNN classiﬁer.from the the ﬁrst class (low degree of infestation)\n",
      "were incorrectly classiﬁed sometimes as a class two\n",
      "(medium degree of infestation), other times as healthy.\n",
      "This is mainly because the three classes’ patterns are\n",
      "characterized by solid invariances in texture and color.\n",
      "Tables 4 and 5 summarize the performance of RF and\n",
      "LightGBM classiﬁers, respectively. When tested using\n",
      "GLCM features only, RF outperformed with an overall\n",
      "accuracy of 91.93% while LightGBM reached 92.63%.\n",
      "The performance of both models will be remarkably\n",
      "increased when tested on combined GLCM and HSV\n",
      "features. RF model outperformed by an average accuracy\n",
      "of 95.42% and an accuracy of 97.52% has been attained\n",
      "by LightGBM.\n",
      "RF and LightGBM classiﬁcation confusion matrices\n",
      "are shown in Figs. 8 and 9, respectively. It is clearly\n",
      "remarkable that the introduction of HSV features\n",
      "improves the discriminative ability of both classiﬁers.\n",
      "However, some samples are misclassiﬁed (ﬁrst and\n",
      "second stage of infestation). As discussed before, this\n",
      "Table 4 Performance comparison of Random Forest\n",
      "classiﬁcation on GLCM only and GLCM+HSV features.\n",
      "ClassPrecision Recall F1-score\n",
      "GLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSV\n",
      "Healthy 0.95 0.98 0.89 0.97 0.92 0.98\n",
      "White\n",
      "scale\n",
      "diseaseStage 1 0.87 0.88 0.88 0.97 0.87 0.92\n",
      "Stage 2 0.89 0.97 0.93 0.88 0.91 0.92\n",
      "Stage 3 0.97 1.00 1.00 0.99 0.98 0.99\n",
      "Macro average 0.92 0.96 0.92 0.95 0.92 0.95\n",
      "Table 5 Performance comparison for LightGBM\n",
      "classiﬁcation on GLCM only and GLCM+HSV features.\n",
      "ClassPrecision Recall F1-score\n",
      "GLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSVGLCM\n",
      "onlyGLCM\n",
      "+HSV\n",
      "Healthy 0.97 0.98 0.90 1.00 0.93 0.99\n",
      "White\n",
      "scale\n",
      "diseaseStage 1 0.90 0.93 0.86 0.98 0.88 0.95\n",
      "Stage 2 0.87 1.00 0.96 0.93 0.91 0.96\n",
      "Stage 3 0.98 1.00 0.99 1.00 0.99 1.00\n",
      "Macro average 0.93 0.98 0.93 0.97 0.93 0.97\n",
      "(a) GLCM only\n",
      " (b) GLCM+HSV\n",
      "Fig. 8 Confusion matrices of RF classiﬁer.270 Big Data Mining and Analytics, September 2023, 6(3): 263–272\n",
      "(a) GLCM only\n",
      " (b) GLCM+HSV\n",
      "Fig. 9 Confusion matrices of LightGBM classiﬁer.\n",
      "is mainly due to the high invariance between the two\n",
      "classes.\n",
      "The performance comparisons of the investigated\n",
      "classiﬁers in terms of overall Accuracy, Precision,\n",
      "Recall, and F1-score are presented in Table 6. It is\n",
      "observed from the results that SVM outperformed\n",
      "with highest precision of 0.92, recall of 0.91, and an\n",
      "accuracy of 98.29% when using the combined GLCM\n",
      "and HSV features. After SVM, LightGBM achieved\n",
      "the highest accuracy of 97.52%. The performance\n",
      "of KNN is better as compared to the performance\n",
      "of RF. Both traditional and ensemble-based machine\n",
      "learning show good results in classifying the degree of\n",
      "infestation by WSD when trained on merged texture\n",
      "and color features. The introduction of HSV color\n",
      "moments contributes to increasing the accuracy. This\n",
      "contribution varies from an insigniﬁcant percentage as\n",
      "remarked in SVM classiﬁer performance to an important\n",
      "percentage for the LightGBM model with about 5.28%\n",
      "of improvement.\n",
      "5 Discussion\n",
      "\n",
      "Extracted Information for C:/Users/pruth/AppData/Roaming/Jupyter/runtime/MLpaper3.pdf:\n",
      "Authors: ['LI LIU\\n', 'Li Liu', 'Ductal Carcinoma', 'Situ', 'Mixed Tumors Breast\\nCancer', 'Breast Cancer', 'Breast Cancer', 'al', 'Breast Cancer', 'VI', 'B. LOGISTICS', 'C. K-NEAREST', 'Fatima', 'G. RANDOM', 'H. K MEAN', 'ANN', 'al', 'Situ', 'Linear Discriminant', 'Random', 'Fatima', 'Naive Bayes', 'Vector Machine', 'Simple Classi', 'Tree', 'Antenna', 'Weka', 'Random', 'Vector Machine', 'Weka', 'Weka', 'Naive Bayes', 'Hyper Parameter\\nOptimization', 'Naive Bayes', 'Breast Cancer', 'Weka', 'WPBC', 'al', 'Euclidean', 'Arti', 'Vector Machine', 'Arti', 'Vector Machine', 'Vector Machine', 'Arti', 'Irvine', 'Neighbours Classi', 'Irvine UCI', 'meta classi', 'Arti', 'Linear Discriminant\\nAnalysis', 'Arti', 'Arti', 'Kappa Statistics', 'Weka', 'Fatima', 'Tree', 'Weka', 'Naive Bayes', 'Naive Bayes', 'Weka', 'Weka', 'Weka', 'Naive Bayes', 'Weka', 'Weka', 'al', 'Breast Cancer', 'DICOM', 'Tanh', 'Maxout', 'Exprecti', 'Naive Bayes', 'Bat', 'Bat', 'Bat', 'Convo-', 'Linux', 'Fatima', 'Ultrasound', 'al', 'Fatima', 'al', 'Machine Learn-', 'Deep Learning', 'Fatima', 'al', 'Deep Learning Algorithms', 'Ensemble Algorithms', 'Sara Al\\nGhunaim', 'Weka', 'Weka', 'Z. Zhao', 'Yang', 'F. Xu', 'H.-J. Lu', 'Zhu', 'W. Shi', 'J. Jiang', 'Yao', 'Zhu', 'J. Biol', 'M. Bahaj', 'Conf', 'Optim', 'Y. Lu', 'J.-Y. Li', 'Y.-T. Su', 'Liu', 'N. Yusoff', 'M. A. Mazurowski', 'L. J. Grimm', 'J. R. Marks', 'L. M. King', 'C. C. Maley', 'Hwang', 'J. Y. Lo', 'Jun.', 'A. Sreedevi', 'Fatima', 'H. Khan', 'J. Med', 'W. D. Dupont', 'L. W. Rogers', 'M. Landenberger', \"F. P. O'Malley\", 'H. Singhal', 'K. S. Tonkin', 'Pathol', 'K. Kim', 'J. Y. Choi', 'D. H. Suh', 'J. H. No', 'Lee', 'Eom', 'H. Kim', 'S. I. Hwang', 'H. J. Lee', 'Y. B. Kim', 'N. Larsson', 'J. Senz', 'N. Boyd', 'P. Kaurah', 'M. J. Kandel', 'L. N. Harris', 'H. C. Pinheiro', 'P. Miron', 'N. Tung', 'C. Oliveira', 'L. Collins', 'S. Schnitt', 'J. E. Garber', 'N. Ozdemir', 'E. E. Ustun', 'Y. Erhan', 'J. Radiol', 'G. Naso', 'C. Raimondi', 'E. Cortesi', 'O. Gandini', 'B. Vincenzi', 'R. Saltarelli', 'E. Chiapparino', 'F. Spremberg', 'M. Cristofanilli', 'A. M. Aglianò', 'P. Gazzaniga', 'Ann', 'M. Bondy', 'W. Yang', 'H. Yamauchi', 'S. Wiggins', 'S. Kamrudin', 'S. Krishnamurthy', 'H. Le-Petross', 'L. Bidaut', 'A. N. Player', 'S. H. Barsky', 'W. A. Woodward', 'N. Ueno', 'M. Cristofanilli', 'Cancer J. Clin', 'P. Chandra', 'J. Inf', 'Technol', 'M. Shaheen', 'S. A. Masood', 'Cancer', 'J.', 'B. Soni', 'S. Reddy', 'Y. Singh', 'H. Kutrani', 'IOSR J. Dental\\nMed', 'I. H. Witten', 'E. Frank', 'Java', 'D. Delen', 'L. Li', 'Y. Wu', 'Y. Ou', 'Q. Li', 'Y. Zhou', 'D. Chen', 'Machine Learning', 'S. Lorwald', 'C. Westermann', 'T. Stadelmann', 'Jun.', 'J. Comput', 'Technol', 'N. A. Taib', 'Y. C. Har', 'S. K. Dhillon', 'G. Tezel', 'J. Seljuk Univ', 'S. Pareek', 'Q. Dai', 'Xu', 'X. Li', 'W. K. Tsai', 'A. Parlos', 'B. Fernandez', 'Joint\\nConf', 'Univ', 'K. R. Joshi', 'J. Electr', 'A. Kardiana', 'R. Yuliwulandari', 'J.\\nAdv.', 'Intell', 'J. Peng', 'K. L. Lee', 'G. M. Ingersoll', 'M. Bolandraftar', 'J. Eng', 'S. Kumar', 'J. Sci', 'M. Imran', 'M. R. Kuppa', 'V. Rajesh', 'Conf', 'Evol', 'Memetic Comput', 'Haviluddin', 'A. H. Kridalaksana', 'M. Wati', 'Technol', 'J. Pandya', 'J. Comput', 'Song', 'L. Ying', 'S. Nagarajan', 'Z. Chen', 'Mag', 'A. I. Hashad', 'N. E. M. Shawky', 'M. Pontil', 'Y. Yang', 'J. Li', 'Y. Yang', 'Conf', 'Technol', 'ICCWAMTIP', 'Mach', 'Learn', 'Mach', 'Y. Li', 'H. Wu', 'Procedia', 'R. Ehrlich', 'W. Full', 'Geosci', 'S. Sihmar', 'A. Jatain', 'X. Hong', 'X. Zhao', 'H. Xin', 'N. Xue', 'J. L. Fernán-', 'V. Makarenkov', 'al', 'A. Dharani', 'B. Santhiya', 'G. R. Lakshmi', 'J. Adv', 'B. Ergen', 'Conf', 'Z. Hu', 'J. Tang', 'Z. Wang', 'K. Zhang', 'L. Zhang', 'Y. Bengio', 'G. Hinton', 'R. Bharuka', 'P. Shah', 'R. Lokare', 'Biologically', 'Cham', 'H. Elahi', 'F. Frezza', 'Cancer', 'I. Shahin', 'I. Attili', 'M. Azzeh', 'F. Ladhak', 'M. Huber', 'Conf', 'Mach', 'M. F. Tolba', 'Cham', 'J. Ferlay', 'I. Soerjomataram', 'R. L. Siegel', 'L. A. Torre', 'A. Jemal', 'Cancer J. Clin', 'L. Hatch', 'C. R. Price', 'S. H. Palakurty', 'E. Simoneit', 'M. Lyman', 'P. Couchot', 'R. Roetzheim', 'L. Guerra', 'E. Gonzalez', 'M. J. Thun', 'Breast Cancer Res', 'S. Jain', 'Frontiers Intell', 'A. Naska', 'R. J. Bello', 'P. Orfanos', 'D. M. Euhus', 'M. A. Manahan', 'C. M. Cooney', 'P. Lagiou', 'G. D. Rosson', 'Tehni£ki Vjesnik', 'H. H. Al-Baity', 'R. R. Ema', 'S. K. Ghosh', 'H. Ahmed', 'T. Islam', 'Cancer', 'Commun', 'Technol', 'J. P. Li', 'M. H. Memon', 'W. Zhou', 'ed recur-\\nsive', 'Mobile Comput', 'L. A. Abd-Elmegid', 'S. Kholeif', 'A. Abdelsamie', 'J. Adv', 'N. Pooja', 'R. A. Reddy', 'P. Chandorkar', 'N. Kazi', 'Technol', 'J. Innov', 'Technol', 'M. Ebrahimi', 'A. R. Razavi', 'P. Kirci', 'T. Ensari', 'M. Zomorodi-Moghadam', 'X. Zhou', 'R. Gururajan', 'X. Tao', 'P. D. Barua', 'R. Gururajan', 'Lett', 'S. Veeramani', 'A. S. Sidhu', 'Mater', 'Jun.', 'Art', 'S. Thakral', 'Commun', 'W. Meira', 'Algorithms', 'J. Comput', 'S. W. Yoon', 'S. S. Lam', 'Expert Syst', 'A. G. Jivani', 'Commun', 'Technol', 'J. Eng', 'Technol', 'G. R. Kumar', 'G. Ramachandra', 'J. Innov', 'Technol', 'J. Mach', 'Learn', 'Jun.', 'E. Guven', 'S. K. Kalita', 'J. Sci.', 'T. Velmurugan', 'Jun.', 'J. A. Balogun', 'A. I. Oluwaranti', 'M. A. Rahman', 'Commun', 'Technol', 'iCEEiCT', 'N. Teeyasuksaet', 'Joint Int', 'Conf', 'Conf', 'Telecommun', 'M. U. Salma', 'Theor', 'Commun', 'Technol', 'L. R. Margolies', 'J. H. Rothstein', 'E. Fluder', 'R. McBride', 'W. Sieh', 'J. Zheng', 'Z. Gao', 'S. Wang', 'M. He', 'Fatima', 'H. Mousannif', 'H. Al Moatassime', 'T. Noel', 'Procedia Comput', 'L. K. Ravi', 'A. Sivasangari', 'E. Al Maghayreh', 'W. Elkilani', 'M. Faisal\\nNagi', 'S. Goel', 'Cloud Comput', 'NOREEN FATIMA', 'Wah Campus', 'LI LIU', 'Abbottabad Campus', 'M.E.']\n",
      "Publication Year: 2020\n",
      "Methods: methodology of cancer detection is based on ``the gold\n",
      "standard'' method that consists of three tests: clinical exam-\n",
      "ination, radiological imaging and pathology test [18]. This\n",
      "conventional method indicates the presence of cancer and it is\n",
      "based on regression process while the new machine learning\n",
      "techniques and algorithms are based on model design. Model\n",
      "is designed for the prediction of unseen data and provides the\n",
      "good expected result in their training and testing stages [19].\n",
      "Machine learning process is based on three main strategies\n",
      "that consists of preprocessing, features selection or extraction\n",
      "and classi\u001c",
      "cation [20]. Feature extraction is the main part of\n",
      "machine learning process and actually helps in diagnosis and\n",
      "prognosis of cancer, this process can elaborate the cancer set\n",
      "in to benign and malignant tumors [21].\n",
      "FIGURE 1. Demonstration of major types of Breast Cancer.\n",
      "Data mining and machine learning algorithms help us for\n",
      "diagnoses and predictions of such types of breast cancer as\n",
      "shown in Figure 1. Data mining techniques [22] such as clas-\n",
      "si\u001c",
      "cation, regression and clustering help us to get the mean-\n",
      "ingful information about the breast cancer patients. These\n",
      "algorithms [23] consist of training dataset, with the help of\n",
      "these datasets we can \u001c",
      "nd chances of prediction of different\n",
      "kinds of breast cancer [24]. This article is divided into differ-\n",
      "ent sections. Section II is about the major machine learning\n",
      "algorithms that are being used for breast cancer prediction,section III is about the major ensemble techniques being used\n",
      "for the prediction of breast cancer, section IV is about the deep\n",
      "learning techniques for breast cancer diagnosis, section V is\n",
      "the survey on breast cancer, section VI is review of different\n",
      "machine learning and deep learning algorithms, section VII\n",
      "is about the study selection and materials that we have used\n",
      "in this research, section VIII provides the discussion\n",
      "Results: results by splitting the data into 50% training and 50% testing\n",
      "test. Dataset was collected from UCI repository university\n",
      "of California named as Irvine. Model was proposed to select\n",
      "the useful information from raw data that was actually con-\n",
      "sisted of 669 records after applying the ensemble method\n",
      "with machine learning algorithms SVM and ANN, theaccuracy level that was achieved through CWV-BANN was\n",
      "higher [53].\n",
      "Sequential Minimal Optimization (SMO) and K Nearest\n",
      "Neighbours Classi\u001c",
      "er (IBk) were used for the prediction of\n",
      "breast cancer with some ensemble approaches. Authors used\n",
      "the data that was consisted of 683 instances and 9 input\n",
      "attributes. Experiment was done through Weka data mining\n",
      "tool, K fold cross validation was used for the evaluation of\n",
      "accuracy of algorithm. The accuracy rate of SMO was found\n",
      "to be 96.19% and IBk algorithm accuracy was found to be\n",
      "95.90% [54].\n",
      "For the automated diagnosis of breast cancer, authors used\n",
      "the nested ensemble techniques with classi\u001c",
      "ers, dataset was\n",
      "collected from Irvine UCI repository that had 32 tumors fea-\n",
      "tures and 569 subjects. In order to analyze the classi\u001c",
      "er for the\n",
      "prediction of tumors, authors applied K fold cross validation,\n",
      "evaluation was done through simple ensemble method and\n",
      "provided the comparative analysis of Naive Bayes classi\u001c",
      "er\n",
      "with Bayes Net. The accuracy of Bayes Net algorithm was\n",
      "found to be 95.25% which was higher than the Naive Bayes\n",
      "Algorithm. Authors also compared the NB and Byes Net\n",
      "with meta classi\u001c",
      "er, the performance of 3rd meta classi-\n",
      "\u001c",
      "er with SV-Naive Bayes was higher than the others meta\n",
      "classi\u001c",
      "ers [80].\n",
      "C. LINEAR AND NONLINEAR ALGORITHM\n",
      "Features selection and features extraction techniques\n",
      "on Arti\u001c",
      "cial Neural Network (ANN), Support Vector\n",
      "Machine (SVM) and Naive Bayes (NB) were applied for the\n",
      "prediction of breast cancer. Dataset of patients was collected\n",
      "from Wisconsin Diagnostic Breast Cancer. Feature selection\n",
      "is a selection of sub features from a huge dataset that helps in\n",
      "computation process. Authors comparatively analyzed each\n",
      "technique with different type of features selection such as\n",
      "coloration based feature selection (CFS), Linear Discriminant\n",
      "Analysis and Recursive Feature Elimination (RFE). After the\n",
      "comparative analysis with different features selection meth-\n",
      "ods, authors came to know that the accuracy rate of Arti\u001c",
      "cial\n",
      "Neural Network was higher than the other algorithms. The\n",
      "accuracy of Support Vector Machine was 96.4%, Arti\u001c",
      "cial\n",
      "Neural Network was 97.0% and Naive Bayes accuracy was\n",
      "91% [81].\n",
      "Data mining tools were used for the prediction of breast\n",
      "cancer, main purpose was to classify Naive Bayes (NB) algo-\n",
      "rithm, Bayesian Logistic Regression, Simple CART and J48\n",
      "on the basis of some parameters. Dataset was collected from\n",
      "Wisconsin Breast Cancer (WBCO). Decision Tree algorithm\n",
      "was used to split whole data into subsets while J48 was based\n",
      "on decision node, these nodes guess the expected data from\n",
      "whole set of data. The main purpose of the author was to \u001c",
      "nd\n",
      "out the best classi\u001c",
      "er on the basis of their Kappa Statistics,\n",
      "Error Rate and their accuracy parameters. The accuracy rate\n",
      "de\u001c",
      "ned the percentage of correctively predicted data. Weka\n",
      "tools was used to analyze all these classi\u001c",
      "ers. After that\n",
      "analysis, authors came to know that Simple CART is more\n",
      "VOLUME 8, 2020 150365N. Fatima et al.: Prediction of Breast Cancer, Comparative Review of Machine Learning Techniques, and Their Analysis\n",
      "appropriate than the other algorithms and it provided the\n",
      "98.13% accuracy [82].\n",
      "Support Vector Machine (SVM), Naive Bayes (NB),\n",
      "K-Nearest Neighbors (KNN) and Classi\u001c",
      "cation And Regres-\n",
      "sion Tree (CART) algorithms were used for breast cancer\n",
      "prediction. Authors compared the data mining algorithms to\n",
      "achieve the best accuracy with less error rate. Analysis was\n",
      "performed using the Weka libraries on the original dataset of\n",
      "Wisconsin Breast Cancer. Dataset consisted of 357 benign\n",
      "patient and 212 records of malignant patients, 80% of data\n",
      "was divided in to train set while 20% data was used for\n",
      "testing, to avoid the over\u001c",
      "tting and under\u001c",
      "tting issues authors\n",
      "used the cross validation, regularization and dropout tech-\n",
      "niques. After analysis the accuracy rate of Support Vector\n",
      "Machine (SVM) was found to be higher than the other data\n",
      "mining algorithms, that provided the 99.1% accuracy [83].\n",
      "For the prediction of breast cancer, Greedy Algorithm was\n",
      "proposed with some constraints search. Constrained Search\n",
      "Sequential Floating Forward Search (CSSFFS) is a feature\n",
      "selection algorithm with Support Vector Machine whose\n",
      "main purpose is to extract some relevant features from a large\n",
      "set of data and it also removes irrelevant features. Dataset for\n",
      "this experiment was collected from machine learning deposi-\n",
      "tory WDBC. CSSFFS was used as hybrid algorithm with Sup-\n",
      "port Vector Machine (SVM), authors used the K Fold cross\n",
      "validation technique on different algorithms, whose main\n",
      "purpose was to extract the irrelevant features and calculate\n",
      "the accuracy rate. Through CSSFFS algorithm, 15 features\n",
      "were selected and CSSFFS increases the accuracy rate of\n",
      "other machine learning algorithms. The accuracy rate of RBF\n",
      "network was 93.6%, Naive Bayes was 92.6%, J48 accuracy\n",
      "rate was 92.9% and simple CART algorithm accuracy rate\n",
      "was 92.9% [84].\n",
      "To get the useful information about the tumors, authors\n",
      "used the hybrid technique by combining the K Mean and\n",
      "SVM algorithm, this hybrid method provided the 97.38%\n",
      "accuracy after the K Fold cross validation process. Dataset\n",
      "was collected from University of California through WDBC\n",
      "center. Six tumor features were selected from 32 original fea-\n",
      "tures. The objective of using hybrid method K-SVM was to\n",
      "predict the tumors whether it is malignant or benign. K-SVM\n",
      "algorithm provided the better performance with minimum\n",
      "error rate [85].\n",
      "D. NONLINEAR AND ENSEMBLE ALGORITHM\n",
      "Decision tree, Naive Bayes and K Nearest Neighbor was\n",
      "applied comparatively on dataset for breast cancer predic-\n",
      "tion. Authors used the Wisconsin original dataset that was\n",
      "collected from UCI machine learning repository. The dataset\n",
      "used had 10 attributes with 458 benign and 241 malignant\n",
      "patients, three major matrices were designed on the basis of\n",
      "two classes: actual healthy and actual not healthy to predict\n",
      "the sensitivity of data. To analyze the performance of each\n",
      "algorithm Weka tool was used, after the comparative analysis\n",
      "of each technique authors came to know that the accuracy\n",
      "of Naive Bayes algorithm was 95.99% which was higherthan the accuracy of decision tree and K Nearest Neighbor\n",
      "(KNN) [86].\n",
      "Authors applied Naive Bayes classi\u001c",
      "ers, Support Vector\n",
      "Machine, K Star, Decision tree and ANN to analyze the\n",
      "patients dataset. The analysis of all algorithms was performed\n",
      "using Weka (Data mining tool). SMO was implemented on\n",
      "RBF kernel. This algorithm normalized all the attributes.\n",
      "KNN was implemented using MLP (Multi-Layer Percep-\n",
      "tron). MLP had input layer, a hidden layer and output layer\n",
      "and K Star algorithm was used to determine the similarity of\n",
      "data. After the comparative analysis of all these algorithms\n",
      "on the dataset of university of medical centre, Institute of\n",
      "Oncology, authors came to know that the accuracy of J48\n",
      "Decision tree was 75.52% which was higher than the all other\n",
      "algorithms [87].\n",
      "Different machine learning algorithms including Decision\n",
      "tree J48, Neural Network, Logistic Regression (LR), Support\n",
      "Vector Machine (SVM) and K Nearest Neighbor (KNN) were\n",
      "used for the prediction of breast cancer. Authors collected\n",
      "the dataset from Wisconsin Breast Cancer (WBC). In order\n",
      "to compare the accuracy of algorithms, Weka tool was used\n",
      "that is based on classi\u001c",
      "cation, association, clustering and\n",
      "visualization of data. The accuracy rate of SVM algorithm\n",
      "was found to be 97.59% which was higher than the all other\n",
      "techniques. Authors evaluated that SVM (Support Vector\n",
      "Machine) was more suitable algorithm for breast cancer pre-\n",
      "diction [88].\n",
      "Comparison of \u001c",
      "ve nonlinear machine learning algorithms\n",
      "including Multi-Layer Perceptron (MLP), K Nearest Neigh-\n",
      "bors (KNN), Classi\u001c",
      "cation And Regression Tree (CART),\n",
      "Support Vector Machines (SVM) and Gaussian Naive Bayes\n",
      "was done for breast cancer detection. Main objective of the\n",
      "author was to compare the ef\u001c",
      "ciency and effectiveness of\n",
      "algorithms for breast cancer detection. Author also measured\n",
      "the accuracy of each algorithm separately. Analysis was\n",
      "performed on Wisconsin breast cancer diagnostics dataset\n",
      "(WBCD). Author used the K Fold validation method to pre-\n",
      "dict the accuracy of each algorithm. The accuracy of MLP\n",
      "was found to be 96.70% which was higher than the KNN,\n",
      "CART and NB algorithm [89].\n",
      "Surveillance Epidemiology and End Result (SEER)\n",
      "database was used to analyze the breast cancer survivability\n",
      "rate. SEER data is more reliable for prediction of differ-\n",
      "ent stages of breast cancer. Authors used three data mining\n",
      "techniques including Naive Bayes, back propagate neural\n",
      "network and C4.5 decision tree algorithm. Comparison was\n",
      "done through data mining tool Weka. Decision tree C4.5 algo-\n",
      "rithm was found to be more appropriate algorithm for breast\n",
      "cancer but it does not include the record of missing data.\n",
      "Survivability of cancer patients was calculated using Weka\n",
      "toolkit that showed the graphical representation of tumor size\n",
      "and its rank, tumor size was higher than its rank. The accuracy\n",
      "of C4.5 algorithm was found to be 86.7% which was higher\n",
      "accuracy than the other algorithms [90].\n",
      "Data mining pre-processing and classi\u001c",
      "cation algorithms\n",
      "was used to detect the breast cancer. After classi\u001c",
      "cation\n",
      "150366 VOLUME 8, 2020N. Fatima et al.: Prediction of Breast Cancer, Comparative Review of Machine Learning Techniques, and Their Analysis\n",
      "of dataset, authors choose two data mining algorithms: J48\n",
      "Decision Tree and ZeroR. ZeroR classi\u001c",
      "er was based on fre-\n",
      "quent analysis of data that was analyzed using the frequency\n",
      "table while J48 machine learning algorithm was applied to\n",
      "predict the value of dependent variable from a dataset of\n",
      "independent variables. Authors used the pathology report to\n",
      "analyze the attributes. On the basis of dataset patterns, author\n",
      "selected some important attributes to predict the occurrence\n",
      "of breast cancer [91].\n",
      "ADTree, J48 and CART algorithm was used to analyze the\n",
      "Breast Cancer dataset of Indian cancer centre Adyar, Chennai\n",
      "and took digital images in the form of DICOM (Digital\n",
      "Imaging and Communication in Medicine). The dataset that\n",
      "authors used was in the form of CSV and authors applied\n",
      "three different data mining algorithms to check the accuracy\n",
      "level. Authors came to know that CART algorithm is more\n",
      "suitable for breast cancer analysis than others, because the\n",
      "accuracy level of CART was 98.50% while the other algo-\n",
      "rithms Adtree and J48 accuracy rate was 97.70% and 98.10%\n",
      "respectively [92].\n",
      "Breast cancer is most common disease in Nigerian women,\n",
      "while in Nigeria there is no prediction and detection of\n",
      "this heterogeneous disease. Authors collected the breast can-\n",
      "cer dataset from LASUTH, cancer registry, Nigeria. Dataset\n",
      "had 17 different breast cancer attributes. Authors used Naive\n",
      "Bayes and J48 decision tree algorithm, Naive Bayes proba-\n",
      "bilistic model is used to handle the number of classes based on\n",
      "probabilistic theory. In J48 decision tree, top to down greedy\n",
      "search was applied on training dataset. Authors came to know\n",
      "that the accuracy level of Naive Bayes was 82.6%, while the\n",
      "accuracy of J48 Decision tree was 94.2% that shows that J48\n",
      "is most suitable algorithm for breast cancer prediction and\n",
      "detection [93].\n",
      "Researchers provided the comparative analysis of Naive\n",
      "Bayes, Random Forest, Logistics Regression, Multi-Layer\n",
      "Perceptron and K Nearest Neighbors for the breast cancer\n",
      "prediction. Evaluation of all these algorithms was performed\n",
      "in terms of Kappa Statistics analysis, TP rate, FP rate and\n",
      "precision of each algorithm. Dataset of Breast Cancer patients\n",
      "was collected from UCI machine learning repository. From\n",
      "dataset, 10 different attributes were collected to predict the\n",
      "breast cancer. Each algorithm was applied on dataset to ana-\n",
      "lyze the accuracy of each algorithm. The accuracy of K Near-\n",
      "est Neighbors, Naive Bayes and Random Forest was 72.3%,\n",
      "71.6% and 69.5% respectively while Logistics Regression\n",
      "and Multi-Layer Perceptron classi\u001c",
      "ed instances accuracy was\n",
      "68.8% and 64.6% respectively [94].\n",
      "E. DEEP LEARNING ALGORITHM\n",
      "To predict the breast cancer on tumor cells, authors used the\n",
      "deep learning technique with different activation functions:\n",
      "Tanh, Recti\u001c",
      "er, Maxout and Exprecti\u001c",
      "er, to provide the com-\n",
      "parative analysis with machine learning algorithms such as\n",
      "Naive Bayes, Decision Tree, Support Vector Machine (SVM)\n",
      "and Random Forest. Wisconsin dataset was used and it\n",
      "had 457 benign class tumors and 241 malignant classtumors. After the comparative analysis of Decision Tree,\n",
      "Naive Bayes, Random Forest and Support Vector Machine\n",
      "(SVM), authors came to know that the accuracy rate of the\n",
      "algorithm using Exponential Recti\u001c",
      "er Linear Unit (ELU)\n",
      "activation function was found to be highest with 96.99%\n",
      "accuracy [95].\n",
      "A model was proposed to predict the reparative appear-\n",
      "ance of breast cancer. This model consisted of two main\n",
      "algorithms: Extreme Learning Machine and Bat algorithm.\n",
      "Bat algorithm was used to create the biases and random\n",
      "weights. The dataset was collected from Wisconsin Breast\n",
      "Cancer Prognostic. The dataset was analyzed on MATLAB\n",
      "tool. The implementation was performed by collecting the\n",
      "relevant attributes from a big dataset. For attributes selection,\n",
      "coef\u001c",
      "cient correlation method was used and after that Bat\n",
      "algorithm and Extreme Learning parameters were applied to\n",
      "check the recurrent and non-recurrent of breast cancer. Deep\n",
      "learning activation functions such as sigmoid, sine and tanh\n",
      "were used to check the testing accuracy on different training\n",
      "stages. Tanh activation function provided the good accuracy\n",
      "than the other activation functions that was 93.75% [96].\n",
      "Deep learning techniques such as Stack Sparse Auto\n",
      "Encoder (SSAE), Sparse Auto Encoder (SAE) and Convo-\n",
      "lutional Neural Network (CNN) were used for the error free\n",
      "detection of breast cancer using mammograms. Preprocess-\n",
      "ing involves the noise removal, background removal and arti-\n",
      "fact suppression. The next step is ROI segmentation that was\n",
      "applied for the detection of tumor by removing the pectoral\n",
      "muscle. The last step was cancer detection for that process,\n",
      "authors provided the input generation, then they construct the\n",
      "deep neural network and after training and testing phase \u001c",
      "nal\n",
      "input was generated. Dataset had 322 digitized images which\n",
      "were actually mammograms. Confusion matrix was designed\n",
      "to analyze the accuracy, sensitivity and precision using MIAS\n",
      "database. The accuracy of SSAE, SAE and CNN was 98.9%,\n",
      "98.5% and 97% respectively. Stack Sparse Auto Encoder\n",
      "provided the good accuracy for the detection of breast cancer\n",
      "in early stages [60].\n",
      "By using end to end training approach authors developed\n",
      "an end to end training for the detection of breast cancer with\n",
      "the help of deep learning algorithm. Analysis was done on\n",
      "Linux workstation, the method was carried out by developing\n",
      "the match and whole images classi\u001c",
      "cation on CBIS-DDSM.\n",
      "Confusion matrix was designed to construct the Resnet 50 and\n",
      "VGG16 patch classi\u001c",
      "ers. Deep learning methodology was\n",
      "used to analyze the cancer patients images, learning ef\u001c",
      "-\n",
      "ciency was analyzed through different training set and visu-\n",
      "alization of images was improved by adding more and more\n",
      "patches around the ROI and in the background [97].\n",
      "To enhance the cancer diagnosis, authors applied the unsu-\n",
      "pervised and deep learning method. Authors initially reduced\n",
      "the dimensionality of features by using PCA method and\n",
      "then they applied the PCA to represent features as a com-\n",
      "pressed structure which were actually encoded through some\n",
      "sample set and randomly selected gene expression. Sparse\n",
      "Auto Encoder technique was applied on multilayers. Authors\n",
      "VOLUME 8, 2020 150367N. Fatima et al.: Prediction of Breast Cancer, Comparative Review of Machine Learning Techniques, and Their Analysis\n",
      "used the learning classi\u001c",
      "er known as Softmax regression to\n",
      "analyze the results [63].\n",
      "For the diagnosis, prognosis and prediction of breast can-\n",
      "cer, authors modularized images into MRI, Digital Images\n",
      "and Ultrasound. Dataset was collected from online open\n",
      "source platform wiki, authors applied deep learning algo-\n",
      "rithms: Autoencoders, CNN and LSTM to achieve the higher\n",
      "level of accuracy, authors proposed the high level learning\n",
      "model Adaboost (DLA-EABS) for \u001c",
      "nal predictions that pro-\n",
      "vided the good accuracy with maximum survival rate. The\n",
      "accuracy of this model was 97.2% [98].\n",
      "FIGURE 3. Paper selection process.\n",
      "VII. OVERVIEW OF STUDY SELECTION\n",
      "For the review of breast cancer predictions, the number of\n",
      "papers that we have considered for study selection at each\n",
      "stage are shown in Figure 3. Total number of papers we have\n",
      "found using keyword search were 43,900 that we have got\n",
      "from different platforms like ACM, IEEE, Research Gate\n",
      "and Science Direct. Our search query was focused on four\n",
      "keywords: machine learning, deep learning, data mining and\n",
      "breast cancer prognosis or diagnosis.\n",
      "Our main aim was to focus on papers that included pre-\n",
      "diction of breast cancer using machine learning and deep\n",
      "learning techniques. We have applied inclusion and exclusion\n",
      "criteria for the selection of relevant material. So, after remov-\n",
      "ing all the duplicate papers, we have selected 110 papers\n",
      "for deep study that was purely related to our research. After\n",
      "thorough study of these papers we have shortlisted 95 papers\n",
      "and \u001c",
      "nally considered for this review. We have considered\n",
      "three channels for our research that are journals, conferences\n",
      "and books. We have reviewed total 64 journal papers, 31\n",
      "conference papers and 7 books.\n",
      "Table 1 demonstrates the selection of paper according to\n",
      "different years, table is divided into journal and conference\n",
      "papers that we have reviewed. The last column in Table 1 isTABLE 1. Year wise number of journal and conference papers.\n",
      "about the total number of papers in one speci\u001c",
      "c year that we\n",
      "have selected for our study. Majority of papers that we have\n",
      "selected for our review analysis are from the last 10 years\n",
      "i.e. 2011-2020 with the maximum number of papers from\n",
      "last year (2019) that give us the information about the breast\n",
      "cancer prediction using machine learning and major deep\n",
      "learning techniques in the present era.\n",
      "FIGURE 4. Number of papers per year.\n",
      "Figure 4 demonstrates the per year frequency of selected\n",
      "research articles in bar plot, it is clearly shown that our main\n",
      "focus is to collect the most recent research papers about the\n",
      "breast cancer prediction. The graph highlights the research\n",
      "papers that we have studied for our breast cancer review. The\n",
      "graph is year based; \u001c",
      "rst we combined number of papers\n",
      "before 2011 then graph is started from the year 2011 and\n",
      "each year shows the number of journal and conference papers\n",
      "that are separately highlighted with two different colors in\n",
      "the graph. We can see that in our review we have maximum\n",
      "number of research papers from last year (2019), in order to\n",
      "\u001c",
      "nd the most recent and appropriate techniques or methods\n",
      "for breast cancer prediction.\n",
      "VIII. DISCUSSION\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "nlp.max_length = 8000000  \n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            content = \"\"\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                content += page.extract_text()  \n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_authors(text):\n",
    "    doc = nlp(text)\n",
    "    authors = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    return authors\n",
    "\n",
    "\n",
    "def extract_publication_year(text):\n",
    "    match = re.search(r\"\\b(19|20)\\d{2}\\b\", text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "\n",
    "def extract_methods_results(text):\n",
    "   \n",
    "    methods_match = re.search(r\"(methods|methodology)(.*?)(results|conclusion|discussion)\", text, re.IGNORECASE | re.DOTALL)\n",
    "    results_match = re.search(r\"(results)(.*?)(conclusion|discussion)\", text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    methods_section = methods_match.group(0) if methods_match else \"Methods section not found\"\n",
    "    results_section = results_match.group(0) if results_match else \"Results section not found\"\n",
    "    return methods_section, results_section\n",
    "\n",
    "\n",
    "def process_paper(pdf_path):\n",
    "    # Extract text from the paper\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        return None \n",
    "    \n",
    "   \n",
    "    authors = extract_authors(text)\n",
    "    publication_year = extract_publication_year(text)\n",
    "    methods, results = extract_methods_results(text)\n",
    "\n",
    "   \n",
    "    extracted_info = {\n",
    "        \"Authors\": authors,\n",
    "        \"Publication Year\": publication_year,\n",
    "        \"Methods\": methods,\n",
    "        \"Results\": results\n",
    "    }\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_paths = [\n",
    "        \"C:/Users/pruth/AppData/Roaming/Jupyter/runtime/MLpaper1.pdf\",\n",
    "        \"C:/Users/pruth/AppData/Roaming/Jupyter/runtime/MLpapre2.pdf\",\n",
    "        \"C:/Users/pruth/AppData/Roaming/Jupyter/runtime/MLpaper3.pdf\"\n",
    "    ]\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        \n",
    "        extracted_info = process_paper(pdf_path)\n",
    "        \n",
    "        if extracted_info:\n",
    "            print(f\"\\nExtracted Information for {pdf_path}:\")\n",
    "            for key, value in extracted_info.items():\n",
    "                print(f\"{key}: {value if value else 'Not found'}\")\n",
    "        else:\n",
    "            print(f\"\\nFailed to process {pdf_path}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db6c2d-e770-40bc-91d6-f369174f27ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
